{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PyTorch lab Installation To follow along, you will need: Python 3.x PyTorch: Machine Learning library Torchvision: Datasets Matplotlib: Visualization Jupyter Lab: Optional. Interactive Python environment in a browser. It might be easiest to install these in a Python virtual environment . $ pip install torch torchvision matplotlib jupyterlab $ jupyter lab Lab sections Tensors : Vectors, matrices, tensors Basic operations Automatic differentiation Digit Classifier : Load MNIST handwritten digit dataset Feed-Forward Neural Network Evaluating a model Training a model Convolutional Neural Network","title":"Home"},{"location":"#pytorch-lab","text":"","title":"PyTorch lab"},{"location":"#installation","text":"To follow along, you will need: Python 3.x PyTorch: Machine Learning library Torchvision: Datasets Matplotlib: Visualization Jupyter Lab: Optional. Interactive Python environment in a browser. It might be easiest to install these in a Python virtual environment . $ pip install torch torchvision matplotlib jupyterlab $ jupyter lab","title":"Installation"},{"location":"#lab-sections","text":"Tensors : Vectors, matrices, tensors Basic operations Automatic differentiation Digit Classifier : Load MNIST handwritten digit dataset Feed-Forward Neural Network Evaluating a model Training a model Convolutional Neural Network","title":"Lab sections"},{"location":"DigitClassifier/","text":"Let's build a digit classifier! Load MNIST training and test set import torch from torchvision import datasets from torchvision.transforms import ToTensor training_data = datasets.MNIST( 'data/', train = True, transform = ToTensor(), download = True) test_data = datasets.MNIST( 'data/', train = False, transform = ToTensor(), download = True) print(len(training_data), len(test_data)) Look at the data (image, label) = training_data[0] print(image) print(image.shape) print(label) Visualize using matplotlib import random from matplotlib import pyplot (image, label) = random.choice(training_data) pyplot.imshow(image[0]) print(label) DataLoader from torch.utils.data import DataLoader train_dataloader = DataLoader(training_data, batch_size=16, shuffle=True) for (index, (features, labels)) in enumerate(train_dataloader): if index == 10: break print(features.shape, features.dtype) print(labels) Feed-Forward Neural Network from torch import nn class DigitClassifierFF(nn.Module): def __init__(self): super().__init__() self.num_hidden = 8 # layers with weights self.layers = nn.Sequential( nn.Flatten(1), # 28 * 28 * 8 = 6272 nn.Linear(28 * 28, self.num_hidden), nn.ReLU(), nn.Linear(self.num_hidden, 10), nn.LogSoftmax(dim=1)) # input: [N, 1, 28, 28] def forward(self, input): log_prob = self.layers(input) return log_prob Instantiate the model digit_classifier_ff = DigitClassifierFF() Try it out import torch import random from matplotlib import pyplot def visualize(model, data): (image, correct_label) = random.choice(test_data) # image: 1 x 28 x 28 print(f'Correct answer: {correct_label}') log_prob = model(image.reshape(1, 1, 28, 28)) # log_prob: 1 x 10 prob = log_prob[0].exp().tolist() fig, axes = pyplot.subplots(1, 2, figsize=(12, 5)) axes[0].imshow(image[0]) axes[1].bar(list(range(10)), prob) pyplot.show() visualize(digit_classifier_ff, test_data) Evaluate the model on test data from torch.utils.data import DataLoader def evaluate(model, data): cost_fn = nn.NLLLoss() data_loader = DataLoader(data, batch_size = 32) cost = 0.0 correct = 0 with torch.no_grad(): for (images, correct_labels) in data_loader: log_prob = model(images) cost += len(images) * cost_fn(log_prob, correct_labels).item() correct += (log_prob.argmax(dim=1) == correct_labels).sum().item() cost /= len(data) correct /= len(data) print(f'Evaluation cost: {cost:.8f} correct: {100 * correct:.2f}%') return cost evaluate(digit_classifier_ff, test_data) Base cost for random guessing torch.tensor(10.0).log() Train DigitClassfierFF from torch import optim def training_epoch(model, data): cost_fn = nn.NLLLoss() data_loader = DataLoader(data, batch_size=32, shuffle=True) optimizer = optim.AdamW(model.parameters(), lr = 0.001) total_cost = 0.0 for (images, labels) in data_loader: log_prob = model(images) cost = cost_fn(log_prob, labels) total_cost += len(images) * cost.item() # backpropagation optimizer.zero_grad() cost.backward() optimizer.step() total_cost /= len(data) print(f'Training cost: {total_cost:.8f}') return total_cost def train(model): training_costs = [] validation_costs = [] for epoch in range(10): training_cost = training_epoch(model, training_data) validation_cost = evaluate(model, test_data) training_costs.append(training_cost) validation_costs.append(validation_cost) return training_costs, validation_costs digit_classifier_ff = DigitClassifierFF() training_costs, validation_costs = train(digit_classifier_ff) Visualize training progress def visualize_cost(training_costs, validation_costs): pyplot.plot(range(len(training_costs)), training_costs, label = 'training') pyplot.plot(range(len(validation_costs)), validation_costs, label = 'validation') pyplot.legend() pyplot.show() visualize_cost(training_costs, validation_costs) Try it out again visualize(digit_classifier_ff, test_data) Inspect first layer weights print(digit_classifier_ff.layers[1]) print(digit_classifier_ff.layers[1].weight.shape) index = 7 image = digit_classifier_ff.layers[1].weight[index].detach().reshape(28, 28) print(image.min(), image.max()) pyplot.imshow(image) Convolutional Neural Network class DigitClassifierCNN(nn.Module): def __init__(self): super().__init__() self.channels_1 = 8 self.channels_2 = 8 self.channels_3 = 8 self.num_hidden = 16 self.layers = nn.Sequential( # 5^2 * 1 * 8 = 200 params nn.Conv2d(1, self.channels_1, 5, padding='same'), # N x 14 x 14 x 8 nn.MaxPool2d(2), nn.ReLU(), # 5^2 * 8 * 8 = 1600 params nn.Conv2d(self.channels_1, self.channels_2, 5, padding='same'), # N x 7 x 7 x 8 nn.MaxPool2d(2), nn.ReLU(), # 5^2 * 8 * 8 = 1600 params nn.Conv2d(self.channels_2, self.channels_3, 5, padding='same'), # N x 4 x 4 x 8 nn.MaxPool2d(2, ceil_mode=True), nn.ReLU(), # N x 128 nn.Flatten(1), # 128 * 16 = 1024 params nn.Linear(4 * 4 * self.channels_3, self.num_hidden), nn.ReLU(), # 16 * 10 = 160 params nn.Linear(self.num_hidden, 10), nn.LogSoftmax(dim=1)) # input: [N, 1, 28, 28] def forward(self, input): log_prob = self.layers(input) return log_prob Try out untrained CNN digit_classifier_cnn = DigitClassifierCNN() visualize(digit_classifier_cnn, test_data) evaluate(digit_classifier_cnn, test_data) Train CNN digit_classifier_cnn = DigitClassifierCNN() training_costs, validation_costs = train(digit_classifier_cnn) visualize_cost(training_costs, validation_costs) Try out trained CNN visualize(digit_classifier_cnn, test_data)","title":"Digit classifier"},{"location":"DigitClassifier/#lets-build-a-digit-classifier","text":"","title":"Let's build a digit classifier!"},{"location":"DigitClassifier/#load-mnist-training-and-test-set","text":"import torch from torchvision import datasets from torchvision.transforms import ToTensor training_data = datasets.MNIST( 'data/', train = True, transform = ToTensor(), download = True) test_data = datasets.MNIST( 'data/', train = False, transform = ToTensor(), download = True) print(len(training_data), len(test_data))","title":"Load MNIST training and test set"},{"location":"DigitClassifier/#look-at-the-data","text":"(image, label) = training_data[0] print(image) print(image.shape) print(label)","title":"Look at the data"},{"location":"DigitClassifier/#visualize-using-matplotlib","text":"import random from matplotlib import pyplot (image, label) = random.choice(training_data) pyplot.imshow(image[0]) print(label)","title":"Visualize using matplotlib"},{"location":"DigitClassifier/#dataloader","text":"from torch.utils.data import DataLoader train_dataloader = DataLoader(training_data, batch_size=16, shuffle=True) for (index, (features, labels)) in enumerate(train_dataloader): if index == 10: break print(features.shape, features.dtype) print(labels)","title":"DataLoader"},{"location":"DigitClassifier/#feed-forward-neural-network","text":"from torch import nn class DigitClassifierFF(nn.Module): def __init__(self): super().__init__() self.num_hidden = 8 # layers with weights self.layers = nn.Sequential( nn.Flatten(1), # 28 * 28 * 8 = 6272 nn.Linear(28 * 28, self.num_hidden), nn.ReLU(), nn.Linear(self.num_hidden, 10), nn.LogSoftmax(dim=1)) # input: [N, 1, 28, 28] def forward(self, input): log_prob = self.layers(input) return log_prob","title":"Feed-Forward Neural Network"},{"location":"DigitClassifier/#instantiate-the-model","text":"digit_classifier_ff = DigitClassifierFF()","title":"Instantiate the model"},{"location":"DigitClassifier/#try-it-out","text":"import torch import random from matplotlib import pyplot def visualize(model, data): (image, correct_label) = random.choice(test_data) # image: 1 x 28 x 28 print(f'Correct answer: {correct_label}') log_prob = model(image.reshape(1, 1, 28, 28)) # log_prob: 1 x 10 prob = log_prob[0].exp().tolist() fig, axes = pyplot.subplots(1, 2, figsize=(12, 5)) axes[0].imshow(image[0]) axes[1].bar(list(range(10)), prob) pyplot.show() visualize(digit_classifier_ff, test_data)","title":"Try it out"},{"location":"DigitClassifier/#evaluate-the-model-on-test-data","text":"from torch.utils.data import DataLoader def evaluate(model, data): cost_fn = nn.NLLLoss() data_loader = DataLoader(data, batch_size = 32) cost = 0.0 correct = 0 with torch.no_grad(): for (images, correct_labels) in data_loader: log_prob = model(images) cost += len(images) * cost_fn(log_prob, correct_labels).item() correct += (log_prob.argmax(dim=1) == correct_labels).sum().item() cost /= len(data) correct /= len(data) print(f'Evaluation cost: {cost:.8f} correct: {100 * correct:.2f}%') return cost evaluate(digit_classifier_ff, test_data)","title":"Evaluate the model on test data"},{"location":"DigitClassifier/#base-cost-for-random-guessing","text":"torch.tensor(10.0).log()","title":"Base cost for random guessing"},{"location":"DigitClassifier/#train-digitclassfierff","text":"from torch import optim def training_epoch(model, data): cost_fn = nn.NLLLoss() data_loader = DataLoader(data, batch_size=32, shuffle=True) optimizer = optim.AdamW(model.parameters(), lr = 0.001) total_cost = 0.0 for (images, labels) in data_loader: log_prob = model(images) cost = cost_fn(log_prob, labels) total_cost += len(images) * cost.item() # backpropagation optimizer.zero_grad() cost.backward() optimizer.step() total_cost /= len(data) print(f'Training cost: {total_cost:.8f}') return total_cost def train(model): training_costs = [] validation_costs = [] for epoch in range(10): training_cost = training_epoch(model, training_data) validation_cost = evaluate(model, test_data) training_costs.append(training_cost) validation_costs.append(validation_cost) return training_costs, validation_costs digit_classifier_ff = DigitClassifierFF() training_costs, validation_costs = train(digit_classifier_ff)","title":"Train DigitClassfierFF"},{"location":"DigitClassifier/#visualize-training-progress","text":"def visualize_cost(training_costs, validation_costs): pyplot.plot(range(len(training_costs)), training_costs, label = 'training') pyplot.plot(range(len(validation_costs)), validation_costs, label = 'validation') pyplot.legend() pyplot.show() visualize_cost(training_costs, validation_costs)","title":"Visualize training progress"},{"location":"DigitClassifier/#try-it-out-again","text":"visualize(digit_classifier_ff, test_data)","title":"Try it out again"},{"location":"DigitClassifier/#inspect-first-layer-weights","text":"print(digit_classifier_ff.layers[1]) print(digit_classifier_ff.layers[1].weight.shape) index = 7 image = digit_classifier_ff.layers[1].weight[index].detach().reshape(28, 28) print(image.min(), image.max()) pyplot.imshow(image)","title":"Inspect first layer weights"},{"location":"DigitClassifier/#convolutional-neural-network","text":"class DigitClassifierCNN(nn.Module): def __init__(self): super().__init__() self.channels_1 = 8 self.channels_2 = 8 self.channels_3 = 8 self.num_hidden = 16 self.layers = nn.Sequential( # 5^2 * 1 * 8 = 200 params nn.Conv2d(1, self.channels_1, 5, padding='same'), # N x 14 x 14 x 8 nn.MaxPool2d(2), nn.ReLU(), # 5^2 * 8 * 8 = 1600 params nn.Conv2d(self.channels_1, self.channels_2, 5, padding='same'), # N x 7 x 7 x 8 nn.MaxPool2d(2), nn.ReLU(), # 5^2 * 8 * 8 = 1600 params nn.Conv2d(self.channels_2, self.channels_3, 5, padding='same'), # N x 4 x 4 x 8 nn.MaxPool2d(2, ceil_mode=True), nn.ReLU(), # N x 128 nn.Flatten(1), # 128 * 16 = 1024 params nn.Linear(4 * 4 * self.channels_3, self.num_hidden), nn.ReLU(), # 16 * 10 = 160 params nn.Linear(self.num_hidden, 10), nn.LogSoftmax(dim=1)) # input: [N, 1, 28, 28] def forward(self, input): log_prob = self.layers(input) return log_prob","title":"Convolutional Neural Network"},{"location":"DigitClassifier/#try-out-untrained-cnn","text":"digit_classifier_cnn = DigitClassifierCNN() visualize(digit_classifier_cnn, test_data) evaluate(digit_classifier_cnn, test_data)","title":"Try out untrained CNN"},{"location":"DigitClassifier/#train-cnn","text":"digit_classifier_cnn = DigitClassifierCNN() training_costs, validation_costs = train(digit_classifier_cnn) visualize_cost(training_costs, validation_costs)","title":"Train CNN"},{"location":"DigitClassifier/#try-out-trained-cnn","text":"visualize(digit_classifier_cnn, test_data)","title":"Try out trained CNN"},{"location":"Tensors/","text":"Intro to PyTorch Tensors import torch Creating vectors a = torch.tensor([1, 2, 3, 4], dtype=torch.float32) print(a) print(a.shape) print(torch.zeros(10)) print(torch.ones(10)) torch.rand(10000) Vector operations a.sum() print(a.sum().shape) print(a.sum().item()) b = torch.tensor([10, 11, 12, 13], dtype=torch.float32) print(b) a + b a * b a ** 2 a.sqrt() a.log() torch.cat([a, b]) a.dot(b) a + 17 a.argmax(0) Matrices A = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32) print(A) print(A.shape) A[0] A[:, 1] A[0, [0, 2]] B = torch.rand([3, 4]) print(B) B @ a # matrix-vector multiplication A @ B # matrix-matrix multiplication B.sum(dim=1) B.mean(dim=0) A.reshape(3, 2) A.flatten() 3D tensors X = torch.tensor([ [[1,2], [3,4]], [[5,6], [7,8]], [[9,10], [11,12]]], dtype=torch.float32) print(X) X @ A Automatic differentiation a = torch.tensor([1.0, 2.0, 3.0, 4.0], requires_grad=True) b = torch.tensor([5.0, 6.0, 7.0, 8.0], requires_grad=True) c = a * b print(c) d = c ** 2 print(d) e = d.sum() print(e) e.backward() print(a.grad) print(b.grad) from torch import nn layer = nn.Softmax(dim=0) a = torch.tensor([-5.0, 1.0, 0.3]) layer(a)","title":"Tensors"},{"location":"Tensors/#intro-to-pytorch-tensors","text":"import torch","title":"Intro to PyTorch Tensors"},{"location":"Tensors/#creating-vectors","text":"a = torch.tensor([1, 2, 3, 4], dtype=torch.float32) print(a) print(a.shape) print(torch.zeros(10)) print(torch.ones(10)) torch.rand(10000)","title":"Creating vectors"},{"location":"Tensors/#vector-operations","text":"a.sum() print(a.sum().shape) print(a.sum().item()) b = torch.tensor([10, 11, 12, 13], dtype=torch.float32) print(b) a + b a * b a ** 2 a.sqrt() a.log() torch.cat([a, b]) a.dot(b) a + 17 a.argmax(0)","title":"Vector operations"},{"location":"Tensors/#matrices","text":"A = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32) print(A) print(A.shape) A[0] A[:, 1] A[0, [0, 2]] B = torch.rand([3, 4]) print(B) B @ a # matrix-vector multiplication A @ B # matrix-matrix multiplication B.sum(dim=1) B.mean(dim=0) A.reshape(3, 2) A.flatten()","title":"Matrices"},{"location":"Tensors/#3d-tensors","text":"X = torch.tensor([ [[1,2], [3,4]], [[5,6], [7,8]], [[9,10], [11,12]]], dtype=torch.float32) print(X) X @ A","title":"3D tensors"},{"location":"Tensors/#automatic-differentiation","text":"a = torch.tensor([1.0, 2.0, 3.0, 4.0], requires_grad=True) b = torch.tensor([5.0, 6.0, 7.0, 8.0], requires_grad=True) c = a * b print(c) d = c ** 2 print(d) e = d.sum() print(e) e.backward() print(a.grad) print(b.grad) from torch import nn layer = nn.Softmax(dim=0) a = torch.tensor([-5.0, 1.0, 0.3]) layer(a)","title":"Automatic differentiation"}]}